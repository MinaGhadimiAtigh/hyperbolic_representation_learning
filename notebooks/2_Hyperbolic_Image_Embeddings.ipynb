{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEXPEfHQxZ-D",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hyperbolic Image Embeddings\n",
    "\n",
    "Welcome to our second notebook for the ECCV 2022 Tutorial \"[Hyperbolic Representation Learning for Computer Vision](https://sites.google.com/view/hyperbolic-tutorial-eccv22)\"!\n",
    "\n",
    "\n",
    "**Open notebook:** \n",
    "[![View filled on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/phlippe/asci_cbl_practicals/blob/master/notebooks/Introduction_to_PyTorch.ipynb)\n",
    "\n",
    "[![Open filled In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/phlippe/asci_cbl_practicals/blob/master/notebooks/Introduction_to_PyTorch.ipynb)\n",
    "\n",
    "**Author:** Mina Ghadimi Atigh"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial, you will go through [Hyperbolic Image Embeddings](https://openaccess.thecvf.com/content_CVPR_2020/papers/Khrulkov_Hyperbolic_Image_Embeddings_CVPR_2020_paper.pdf), CVPR 2020 paper. The paper argues that hyperbolic spaces with negative curvature might often be more appropriate for learning the embedding of images. It shows that many image classification architectures, in particular the few-shot learning setting, can be easily modified to operate on hyperbolic embeddings, which in many cases also leads to improvements.\n",
    "\n",
    "In this tutorial, you will go through the hyperbolic *Few-shot learning* task. Few-shot learning aims to classify new data given only a few training samples with supervised information. The few-shot learning task is formulated as N-way K-shot, in which N is the number of classes to classify and K is the number of samples given for each class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qucLFCIGcMy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start with installing and importing libraries. Also, we set a manual seed using `set_seed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqsBtgrZOrdq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/leymir/hyperbolic-image-embeddings/6633edbbeffd6d90271f0963852a046c64f407d6/examples/fewshot/networks/convnet.py\n",
    "!pip install git+https://github.com/geoopt/geoopt.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6csDjdMFOYIS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## standard libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import random\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "## PyTorch Torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "## geoopt for hyperbolic  \n",
    "import geoopt\n",
    "\n",
    "## Neural network downloaded from paper's GitHub\n",
    "from convnet import ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nVWHt_dCQsp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function for setting the seed\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kdB4QmUbyDh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Throughout this tutorial, you will work with _CUB-200-2011_ Dataset. The CUB dataset consists of 11788 images of 200 bird classes. In the experiments, 100 classes are used for training, 50 for validation, and 50 for testing. The code starts with downloading the dataset first. \n",
    "\n",
    "Using the code, you can download the data to the path `data/cub`. Images will be saved in `data/cub/images`. Train, val, and test splits will be saved in `data/cub/split`. Also, there will be a `data/cub/classes.txt` file, containing the names of the 200 classes, which will be used for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3u5f6fievwuD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "%mkdir data\n",
    "%mkdir data/cub\n",
    "%cd data/cub\n",
    "!wget -q -O tmp.tgz https://data.caltech.edu/tindfiles/serve/1239ea37-e132-42ee-8c09-c383bb54e7ff/\n",
    "!tar -xzvf tmp.tgz\n",
    "!rm tmp.tgz\n",
    "!rm attributes.txt\n",
    "%mkdir images\n",
    "!mv CUB_200_2011/images/*/*.jpg images\n",
    "!mv CUB_200_2011/classes.txt classes.txt\n",
    "!rm -r CUB_200_2011\n",
    "clear_output()\n",
    "\n",
    "%mkdir split\n",
    "%cd split\n",
    "![ ! -f test.csv ] && wget https://raw.githubusercontent.com/leymir/hyperbolic-image-embeddings/master/examples/fewshot/data/cub/split/test.csv\n",
    "![ ! -f val.csv ] && wget https://raw.githubusercontent.com/leymir/hyperbolic-image-embeddings/master/examples/fewshot/data/cub/split/val.csv\n",
    "![ ! -f train.csv ] && wget https://raw.githubusercontent.com/leymir/hyperbolic-image-embeddings/master/examples/fewshot/data/cub/split/train.csv\n",
    "%cd ../../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCJ53D7Md7zg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next step is to handle data loader functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QbSYQXtxnHnV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ROOT to the images and split, data files are available here.\n",
    "ROOT_PATH = os.getcwd()\n",
    "DATA_PATH = os.path.join(ROOT_PATH, \"data/cub/\")\n",
    "IMAGE_PATH = os.path.join(DATA_PATH, \"images\")\n",
    "SPLIT_PATH = os.path.join(DATA_PATH, \"split\")\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "transformtypedict = dict(\n",
    "    Brightness=ImageEnhance.Brightness,\n",
    "    Contrast=ImageEnhance.Contrast,\n",
    "    Sharpness=ImageEnhance.Sharpness,\n",
    "    Color=ImageEnhance.Color,\n",
    ")\n",
    "\n",
    "\n",
    "class ImageJitter(object):\n",
    "    def __init__(self, transformdict):\n",
    "        self.transforms = [(transformtypedict[k], transformdict[k]) for k in transformdict]\n",
    "\n",
    "    def __call__(self, img):\n",
    "        out = img\n",
    "        randtensor = torch.rand(len(self.transforms))\n",
    "        for i, (transformer, alpha) in enumerate(self.transforms):\n",
    "            r = alpha * (randtensor[i] * 2.0 - 1.0) + 1\n",
    "            out = transformer(out).enhance(r).convert(\"RGB\")\n",
    "        return out\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# This is for the CUB dataset, which does not support the ResNet encoder now\n",
    "# It is notable, we assume the cub images are cropped based on the given bounding boxes\n",
    "# The concept labels are based on the attribute value, which are for further use (and not used in this work)\n",
    "class CUB(Dataset):\n",
    "    def __init__(self, setname):\n",
    "        txt_path = os.path.join(SPLIT_PATH, setname + \".csv\")\n",
    "        lines = [x.strip() for x in open(txt_path, \"r\").readlines()][1:]\n",
    "        data = []\n",
    "        label = []\n",
    "        lb = -1\n",
    "        self.wnids = []\n",
    "\n",
    "        for l in lines:\n",
    "            context = l.split(\",\")\n",
    "            name = context[0]\n",
    "            wnid = context[1]\n",
    "            path = os.path.join(IMAGE_PATH, name)\n",
    "            if wnid not in self.wnids:\n",
    "                self.wnids.append(wnid)\n",
    "                lb += 1\n",
    "\n",
    "            data.append(path)\n",
    "            label.append(lb)\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.num_class = np.unique(np.array(label)).shape[0]\n",
    "\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "        if setname == \"train\":\n",
    "            self.transform = transforms.Compose([transforms.RandomResizedCrop(84),\n",
    "                                                 ImageJitter(dict(Brightness=0.4, Contrast=0.4, Color=0.4)),\n",
    "                                                 transforms.RandomHorizontalFlip(),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(np.array([0.485, 0.456, 0.406]),\n",
    "                                                                      np.array([0.229, 0.224, 0.225])),\n",
    "                                                 ])\n",
    "\n",
    "        else:\n",
    "            self.transform = transforms.Compose([transforms.Resize(84, interpolation=PIL.Image.BICUBIC),\n",
    "                                                 transforms.CenterCrop(84),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 normalize, ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        path, label = self.data[i], self.label[i]\n",
    "        x = Image.open(path).convert(\"RGB\")\n",
    "        image = self.transform(Image.open(path).convert(\"RGB\"))\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "class CategoriesSampler:\n",
    "    def __init__(self, label, n_batch, n_cls, n_per):\n",
    "        self.n_batch = n_batch\n",
    "        self.n_cls = n_cls\n",
    "        self.n_per = n_per\n",
    "\n",
    "        label = np.array(label)\n",
    "        self.m_ind = []\n",
    "        for i in range(max(label) + 1):\n",
    "            ind = np.argwhere(label == i).reshape(-1)\n",
    "            ind = torch.from_numpy(ind)\n",
    "            self.m_ind.append(ind)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batch\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i_batch in range(self.n_batch):\n",
    "            batch = []\n",
    "            classes = torch.randperm(len(self.m_ind))[: self.n_cls]\n",
    "            for c in classes:\n",
    "                l = self.m_ind[c]\n",
    "                pos = torch.randperm(len(l))[: self.n_per]\n",
    "                batch.append(l[pos])\n",
    "            batch = torch.stack(batch).t().reshape(-1)\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyU1dgz2a0gO",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Exctract class names of the CUB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCHUo2XObHRk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classname_file = os.path.join(DATA_PATH, 'classes.txt')\n",
    "class_dict = {}\n",
    "with open(classname_file) as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        class_num = int(line.split(' ')[0])\n",
    "        class_dict[class_num - 1] = line.split('.')[1].split('\\n')[0].replace('_', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIvu81r5VuLk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Before starting the main task, let's check how images from the dataset look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSDIoLDxZayh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define a sample trainset\n",
    "sample_trainset = CUB(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrKGPN02g6vx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# number of images to plot\n",
    "NUM_IMAGES = 4\n",
    "# Index of images to plot\n",
    "indexes = random.sample(range(len(sample_trainset)), NUM_IMAGES)\n",
    "images = [sample_trainset[idx][0] for idx in indexes]\n",
    "labels = [sample_trainset[idx][1] for idx in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FyYBjZL8WnaX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img_grid = torchvision.utils.make_grid(images, nrow=8, normalize=True, pad_value=0.9)\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title(\"Examples of CUB dataset\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print('  |  '.join(f'{class_dict[labels[j]]:16s}' for j in range(NUM_IMAGES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WLYRpiPiRTj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Few Shot learning: Euclidean and Hyperbolic Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdpHPlb0jvHU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, we set the value of hyperparameters, assigned using `Config`. The hyperparameters are set for 5-way 1-shot task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVy4wmo3jtgt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, shot=1, lr=0.001, step=50, gamma=0.8, c=0.05, model=\"convnet\", hyperbolic = True, dim=1600,\n",
    "                 query=15, way=5, validation_way=5, temperature=1, dataset=\"CUB\", lr_decay=True, max_epoch=200):\n",
    "        \n",
    "        self.lr = lr                                  # learning rate\n",
    "        self.lr_decay = lr_decay                      # Boolean, if to perform learning rate scheduler\n",
    "        self.step_size=step                           # Period of learning rate decay\n",
    "        self.gamma = gamma                            # Multiplicative factor of learning rate decay\n",
    "        self.dataset= dataset                         # Dataset name\n",
    "        self.model = \"convnet\"                        # Name of Base Model\n",
    "        self.temperature = temperature                # temperature used in calculating logits\n",
    "        self.max_epoch=max_epoch                      # number of epochs\n",
    "\n",
    "        self.c = c                                    # Curvature of the hyperbolic space\n",
    "        self.hyperbolic = hyperbolic                  # Boolean, if it is hyperbolic or not\n",
    "        self.dim = dim                                # dimenionality of the output vector\n",
    "\n",
    "        self.shot = shot                              # Number of shots in Few shot learning task\n",
    "        self.query = query                            #\n",
    "        self.way = way                                # Number of ways in Few shot learning task\n",
    "        self.validation_way = validation_way          # Number of ways in Few shot learning task for validation set\n",
    "\n",
    "\n",
    "args = Config(dim=512, max_epoch = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imLdXgEPs3E5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Split training and validation set based on the `Config` for few-shot learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8g8TRexj3so",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainset = CUB(\"train\")\n",
    "train_sampler = CategoriesSampler(trainset.label, 100, args.way, args.shot + args.query)\n",
    "train_loader = DataLoader(dataset=trainset, batch_sampler=train_sampler, num_workers=8, pin_memory=True)\n",
    "\n",
    "valset = CUB(\"val\")\n",
    "val_sampler = CategoriesSampler(valset.label, 500, args.validation_way, args.shot + args.query)\n",
    "val_loader = DataLoader(dataset=valset, batch_sampler=val_sampler, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Er3045V3tJ7B",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, it's time to define the model. Structure of the model is based on \"[Prototypical Networks for Few-shot Learning (ProtoNet)](https://papers.nips.cc/paper/2017/file/cb8da6767461f2812ae4290eac7cbc42-Paper.pdf)\", NeurIPS 2017 paper. Hyperbolic Image Embeddings has picked ProtoNet because it is simple in general and simple to convert to hyperbolic geometry. ProtoNets use the so-called **prototype representation** of a class, which is defined as a **mean of the embedded support set of a class**. To generalize this concept to hyperbolic space, Euclidean mean is substituted by *hyperbolic average*.\n",
    "\n",
    "Once the prototypes are calculated based on the average of data points, it's time to calculate the distance of the data points with the prototypes and perform classificatin based on the calculated logits. To calculate the distance in the hyperbolic space, *Hyperbolic distance* is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgkVYwnFxg9_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Hyperbolic Average\n",
    "\n",
    "Let's first define Hyperbolic average. Extension of Euclidean average to hyperbolic space is called *Einsterin midpoint*, which takes the most simple form in *Klein* coordinates.\n",
    "\n",
    "\\begin{align}\n",
    "HypAve(x_1, ..., x_N) = \\frac{\\sum_{i=1}^N \\gamma_i x_i}{\\sum_{i=1}^N \\gamma_i}\n",
    "\\end{align}\n",
    "\n",
    "where $\\gamma_i = \\frac{1}{\\sqrt{1-c\\| x_i \\|^2}}$ are the Lorentz factors. The Lorentz factors is implemented in `lorenz_factor` function.\n",
    "\n",
    "HypAve is in Klein coordinates. Therefore it is necessary to transfer the points to the Klein model first and then project the calculated average onto the Poincare model.\n",
    "\n",
    "Let $x_\\mathbb{D}$ and $x_\\mathbb{K}$ denote the coordinates of the same point in the Poincare and Klein models. To project the points between these models, the following equations are needed.\n",
    "\n",
    "\\begin{align}\n",
    "x_\\mathbb{D} = \\frac{x_\\mathbb{K}}{1 + \\sqrt{1 - c\\|x_\\mathbb{K}\\|^2}}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "x_\\mathbb{K} = \\frac{2x_\\mathbb{D}}{1 + c\\|x_\\mathbb{D}\\|^2}\n",
    "\\end{align}\n",
    "\n",
    "These projecttions are implemented in `k2p` and `p2k` functions. Finally, $HypAve$ is implements in `poincare_mean` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpgTlZhb6RYL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def lorenz_factor(x, *, c=1.0, dim=-1, keepdim=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : tensor\n",
    "        point on Klein disk\n",
    "    c : float\n",
    "        negative curvature\n",
    "    dim : int\n",
    "        dimension to calculate Lorenz factor\n",
    "    keepdim : bool\n",
    "        retain the last dim? (default: false)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tensor\n",
    "        Lorenz factor\n",
    "    \"\"\"\n",
    "    return 1 / torch.sqrt(1 - c * x.pow(2).sum(dim=dim, keepdim=keepdim))\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Project a point from Klein model to Poincare model\n",
    "def k2p(x, c):\n",
    "    denom = 1 + torch.sqrt(1 - c * x.pow(2).sum(-1, keepdim=True))\n",
    "    return x / denom\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Project a point from Poincare model to Klein model\n",
    "def p2k(x, c):\n",
    "    denom = 1 + c * x.pow(2).sum(-1, keepdim=True)\n",
    "    return 2 * x / denom\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "def poincare_mean(x, dim=0, c=1.0):\n",
    "    # To calculate the mean, another model of hyperbolic space named Klein model is used.\n",
    "    # 1. point is projected from Poincare model to Klein model using p2k, output x is a point in Klein model\n",
    "    x = p2k(x, c)\n",
    "    # 2. mean is calculated\n",
    "    lamb = lorenz_factor(x, c=c, keepdim=True)\n",
    "    mean = torch.sum(lamb * x, dim=dim, keepdim=True) / torch.sum(lamb, dim=dim, keepdim=True)\n",
    "    # 3. Mean is projected from Klein model to Poincare model\n",
    "    mean = k2p(mean, c)\n",
    "    return mean.squeeze(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmDsLu4j87no",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, it's time to define the model `ProtoNet`. Whether `args.hyperbolic` is *True* of *False*, the model can be Hyperbolic or Euclidean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evNlG8NoiwVQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ProtoNet(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "\n",
    "        # Base Model: ConvNet\n",
    "        self.encoder = ConvNet(z_dim=args.dim)\n",
    "\n",
    "        # If working in Hyperbolic Space\n",
    "        if args.hyperbolic:\n",
    "            self.manifold = geoopt.PoincareBall(c=args.c)\n",
    "\n",
    "    def forward(self, data_shot, data_query):\n",
    "        # 1. feed data to the model\n",
    "        proto = self.encoder(data_shot)\n",
    "        \n",
    "        # Hyperbolic Space:\n",
    "        if self.args.hyperbolic:\n",
    "            # 2. encoder is Euclidean, so proto is in Euclidean space and should be projected to Hyperboolic space using exponential map\n",
    "            proto = self.manifold.expmap0(proto)\n",
    "            \n",
    "            if self.training:\n",
    "                proto = proto.reshape(self.args.shot, self.args.way, -1)\n",
    "            else:\n",
    "                proto = proto.reshape(self.args.shot, self.args.validation_way, -1)\n",
    "\n",
    "            # 3. calculate prototypes based on mean of data\n",
    "            proto = poincare_mean(proto, dim=0, c=self.manifold.c.item())\n",
    "            \n",
    "            # 4. query is projected to hyperbolic space too\n",
    "            data_query = self.manifold.expmap0(self.encoder(data_query))\n",
    "            \n",
    "            # 5. Logits is calculated based on the Hyperbolic distance between data query and proto\n",
    "            logits = (-self.manifold.dist(data_query[:, None, :], proto) / self.args.temperature)\n",
    "\n",
    "        # Euclidean Space\n",
    "        else:\n",
    "            # 2. calculate prototypes based on mean of data\n",
    "            if self.training:\n",
    "                proto = proto.reshape(self.args.shot, self.args.way, -1).mean(dim=0)\n",
    "            else:\n",
    "                proto = proto.reshape(self.args.shot, self.args.validation_way, -1).mean(dim=0)\n",
    "            \n",
    "            # 3. Logits is calculated based on the Euclidean distance between data query and proto\n",
    "            logits = (((self.encoder(data_query)[:, None, :] - proto)**2).sum(dim=-1) / self.args.temperature)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = ProtoNet(args).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-El1RFHIIFe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once the model is defined, it's time for the training loop. Let's first define *optimizer* and *learning rate scheduler*, alongside with functions to calculate accuracy and average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNGO4PiDIWsK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "if args.lr_decay:\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WTG2rPBJcfa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy given logits and groundtruth labels\n",
    "def count_acc(logits, label):\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    if torch.cuda.is_available():\n",
    "        return (pred == label).type(torch.cuda.FloatTensor).mean().item()\n",
    "    else:\n",
    "        return (pred == label).type(torch.FloatTensor).mean().item()\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Class defined to average the values passed to it\n",
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "        self.v = 0\n",
    "\n",
    "    def add(self, x):\n",
    "        self.v = (self.v * self.n + x) / (self.n + 1)\n",
    "        self.n += 1\n",
    "\n",
    "    def item(self):\n",
    "        return self.v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXHCH8bumdZ-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Training loop\n",
    "Next step is training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7Y6_MSKI8bg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, args.max_epoch + 1):\n",
    "    if args.lr_decay:\n",
    "        lr_scheduler.step()\n",
    "    model.train()\n",
    "    \n",
    "    tl = Averager()\n",
    "    ta = Averager()\n",
    "\n",
    "    label = torch.arange(args.way).repeat(args.query)\n",
    "    if torch.cuda.is_available():\n",
    "        label = label.type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        label = label.type(torch.LongTensor)\n",
    "\n",
    "    for i, batch in enumerate(train_loader, 1):\n",
    "        if torch.cuda.is_available():\n",
    "            data, _ = [_.cuda() for _ in batch]\n",
    "        else:\n",
    "            data = batch[0]\n",
    "        p = args.shot * args.way\n",
    "        data_shot, data_query = data[:p], data[p:]\n",
    "        logits = model(data_shot, data_query)\n",
    "        loss = F.cross_entropy(logits, label)\n",
    "        acc = count_acc(logits, label)\n",
    "\n",
    "        print(\"epoch {}, train {}/{}, loss={:.4f} acc={:.4f}\".format(epoch, i, len(train_loader), loss.item(), acc))\n",
    "        \n",
    "        tl.add(loss.item())\n",
    "        ta.add(acc)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    tl = tl.item()\n",
    "    ta = ta.item()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    vl = Averager()\n",
    "    va = Averager()\n",
    "\n",
    "    label = torch.arange(args.validation_way).repeat(args.query)\n",
    "    if torch.cuda.is_available():\n",
    "        label = label.type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        label = label.type(torch.LongTensor)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader, 1):\n",
    "            if torch.cuda.is_available():\n",
    "                data, _ = [_.cuda() for _ in batch]\n",
    "            else:\n",
    "                data = batch[0]\n",
    "            p = args.shot * args.validation_way\n",
    "            data_shot, data_query = data[:p], data[p:]\n",
    "            logits = model(data_shot, data_query)\n",
    "            loss = F.cross_entropy(logits, label)\n",
    "            acc = count_acc(logits, label)\n",
    "\n",
    "            vl.add(loss.item())\n",
    "            va.add(acc)\n",
    "\n",
    "    vl = vl.item()\n",
    "    va = va.item()\n",
    "    print(\"epoch {}, val, loss={:.4f} acc={:.4f}\".format(epoch, vl, va))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJGSuTuEm89j",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Testing function\n",
    "\n",
    "Once the training is complete, it's time to see model's performance on the test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2CheVhrpB9x",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, let's create test dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_mN8kGzpKfZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_set = CUB(\"test\")\n",
    "test_sampler = CategoriesSampler(test_set.label, 1000, args.validation_way, args.shot + args.query)\n",
    "test_loader = DataLoader(test_set, batch_sampler=test_sampler, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7IEv3rGSWV_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_confidence_interval(data):\n",
    "    \"\"\"\n",
    "    Compute 95% confidence interval\n",
    "    :param data: An array of mean accuracy (or mAP) across a number of sampled episodes.\n",
    "    :return: the 95% confidence interval for this data.\n",
    "    \"\"\"\n",
    "    a = 1.0 * np.array(data)\n",
    "    m = np.mean(a)\n",
    "    std = np.std(a)\n",
    "    pm = 1.96 * (std / np.sqrt(len(a)))\n",
    "    return m, pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5ysZsZbpWbx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "ave_acc = Averager()\n",
    "test_acc_record = np.zeros((1000,))\n",
    "\n",
    "label = torch.arange(args.validation_way).repeat(args.query)\n",
    "if torch.cuda.is_available():\n",
    "    label = label.type(torch.cuda.LongTensor)\n",
    "else:\n",
    "    label = label.type(torch.LongTensor)\n",
    "\n",
    "# Testing loop\n",
    "for i, batch in enumerate(test_loader, 1):\n",
    "    if torch.cuda.is_available():\n",
    "        data, _ = [_.cuda() for _ in batch]\n",
    "    else:\n",
    "        data = batch[0]\n",
    "    k = args.validation_way * args.shot\n",
    "    data_shot, data_query = data[:k], data[k:]\n",
    "\n",
    "    logits = model(data_shot, data_query)\n",
    "    acc = count_acc(logits, label)\n",
    "    ave_acc.add(acc)\n",
    "    test_acc_record[i - 1] = acc\n",
    "\n",
    "m, pm = compute_confidence_interval(test_acc_record)\n",
    "print(\"Test Acc {:.4f} + {:.4f}\".format(m, pm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odWSkswZyCCo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As mentioned when defining `ProtoNet`, if `args.hyperbolic` is True, the model will be hyperbolic, Euclidean otherwise. To compare the performance of ProtoNet in hyperbolic and Euclidean manifolds, we train both of them for the same number of epochs. When training both models for $5$ epochs, the test accuracy of hyperbolic ProtoNet is around $39.99%$, while Euclidean ProtoNet results in an accuracy of $17.94%$. The paper also comes to a similar conclusion too. Based on the results provided in the paper, when training hyperbolic and Euclidean ProtoNet for $50$ epochs, the Euclidean version results in $51.31%$, while the hyperbolic one results in $64.02%$, which outperforms Euclidean one by more than $10%$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}